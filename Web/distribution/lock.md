# [分布式锁](#lock)

---

单机场景下语言内置的锁就能够实现同步，但是分布式下需要同步的进程处于不同机器上，所以需要分布式锁

同单机情况下，分布式锁也需要满足几个条件：

* 互斥：同一资源任何时刻只能存在一个 client 持有锁
* 无死锁：出现问题时要能够释放锁，避免死锁
* 可重入：同一个 client 上的同一个线程如果获取了锁之后那么也可以再次获取这个锁
* 一致：硬件故障或网络异常等外部问题，以及慢查询、自身缺陷等内部因素都可能导致 Redis 发生高可用切换，锁需要在切换到新的 master 后保持原状态
* 非阻塞：和 ReentrantLock 一样支持 lock 和 trylock 以及 tryLock(long timeOut)

## 1. 基于 db

向表中成功插入一条记录表示获得了锁，删除记录表示释放了锁，**唯一索引**可以保证只有一个插入操作成功

* 互斥：唯一索引保证
* 无死锁：解锁失败会导致锁记录一直存在于表中，其他线程无法获取，需要借助定时任务清理表中的超时数据
* 可重入：同一个线程获取锁后无法再次 insert，因为记录已经存在了，可以在锁记录中记录相关数据，下次获取锁时先查询锁记录，对于同一节点就可以不用再次 insert
* 一致：由 db 的同步机制保证
* 非阻塞：insert 失败会直接返回，没有获取到锁的线程不会阻塞

## 2. [基于 Redis](#redis_lock)

**加锁**：

```Shell
SET key value NX EX seconds
```

* key：分布式锁的 key
* value：分布式锁的值
* NX：如果要设置的 key 已存在，则取消设置
* EX：表示过期时间为秒，PX 则为毫秒

**解锁**：A 获取锁后锁超时为 5s，但 5s 内 A 代码未执行完，锁释放，此时 B 获取到了锁，A 执行完成后释放了 B 的锁。为了避免此问题，分布式锁的是否需要持有者自己释放，需要确保当前释放锁的线程是持有者，确认无误在删除，这两步操作需要保证原子性，可以使用 lua 脚本拼装，再使用 redis 的 eval 函数执行脚本：

```lua
if redis.call("get", KEYS[1]) == ARGV[1]
then
    return redis.call("del", KEYS[1])
else
    return 0
end
```

### 2.1 互斥

即使使用了 set 命令，仍存在出现并发获取锁的问题：

**锁超时**：A 获取锁后锁超时为 5s，但 5s 内 A 代码未执行完，锁释放，此时 B 获取到了锁，除了修改超时时间外，可以使用定时任务对锁进行续约，同解锁一样，client 只能续租自己加的锁：

```lua
if redis.call("get",KEYS[1]) == ARGV[1]
then
    return redis.call("expire", KEYS[1], ARGV[2])
else
    return 0
end
```

### 2.1 无死锁

设置锁超时时间即可

### 2.3 可重入

使用 hash 存储锁，同一个线程再次获取锁时 hash 的 value+1

### 2.4 一致

* 故障转移：如果 redis 是单 master 模式的，当 master 节点宕机时，所有的客户端都会获取不到锁，为了提高可用性，一般会给这个 master 增加 slave 节点，但是因为 redis 的主从同步是异步进行的，可能会出现客户端 1 设置完锁后，master 挂掉，slave 提升为 master，因为异步复制的特性，客户端 1 设置的锁丢失了，这时候客户端 2 设置锁也能够成功，导致客户端 1 和客户端 2 同时拥有锁
* 时钟漂移：如果 redis 服务器的机器时钟发生了向前跳跃，就会导致这个 key 过早超时失效，比如说客户端 1 拿到锁后，key 的过期时间是 12:02 分，但 redis 服务器本身的时钟比客户端快了 2 分钟，导致 key 在 12:00 的时候就失效了，这时候，如果客户端 1 还没有释放锁的话，就可能导致多个客户端同时持有同一把锁

以上问题使用 redlock 算法可以解决但无法完全解决，即使使用 redission 也存在问题，因为对于 redis 来说本身就不是强一致性，要想保持强一致性，需要使用 zookeeper，但性能比 redis 稍差

### 2.5 非阻塞

获取锁失败返回 false 即可
