## 1. CAP

CAP 指一致性（Consistency）、可用性（Availability）、分区容忍性（Partition Tolerance），分布式系统的这三者无法同时满足

* C：每次请求读到的都是最新的数据或错误信息
* A：每次请求都能获得非错误的响应，但不能保证数据是最新的
* P：节点间丢失数据或节点不可用，系统还可以对外提供服务

> 如何理解 CAP 的「三选二」？
> 保存数据的节点越多， P 就越高，但需同步的数据就越多，C 就越难保证，而为了保证 C，每次同步数据就需要等待各个节点的统一，会导致 A 的降低

* CP：zookeeper，任何时刻对 zookeeper 的访问都能得到一致的结果
* AP：
	* 高并发的网站，如 12306
	* 集群模式下的 redis，节点故障时可能会存在数据的不一致

### 1.1 一致性

* 强一致性：单机下的 MySQL，由 ACID 保证强一致性
* 弱一致性：数据库和缓存的一致性
* 最终一致性：基于本地消息表的分布式事务

### 1.2 可用性

* BA（Basically Available）：基本可用，就是说分布式系统在核心可用下允许部分故障
* S（Soft State）：软状态，不影响系统整体可用性下允许数据存在中间状态，如数据正在同步
* E（Eventually Consistency）：最终一致性，需要注意的是 **ACID 要求的是强一致性**

#### 双机房实时热备

* redis

* mysql

### 1.3 分区容忍性

* 一致性 hash 解决扩缩容问题
* 提升基础设施的稳定性

## 2. 分布式 ID

* 基于 MySQL 的 auto_increament 属性，但是会强依赖于数据库，需要提高数据库可靠性
* 使用本地 UUID，但生成的 ID 无序，不适用于作主键，因为无序的主键会导致 B+  树的结构频繁变动
* 采用时间戳拼接业务 ID，但并发足够高时就无法保证唯一性
* Twitter 雪花算法

当对 ID 生成器的请求次数很高时，还需要保证 ID 的唯一性，就需要加锁，如何提高生成器的性能？

* 给全局 ID 生成器安装多个前置发号器。批量地给每个前置发号器发送特定范围内的 ID，多个前置发号器提高了并发能力
* 直接使用多个 ID 生成器，每个生成器按照一定规则 ID，互不干扰

## 3. 分布式缓存

### 3.1 缓存负载策略

一致性 hash 算法：

* 场景：n 台机器缓存数据，使用 `hash() % n` 的方式将数据分散存储，在访问数据时使用同样的方式可直接获取到目标机器
* 问题：机器数量变动，大量缓存同时失效，出现缓存雪崩
* **hash 环**：将 hash 空间 [0, 2^32-1] 看作一个环，使用 `hash（机器唯一标识） % 2^32` 得到的机器在 hash 环中的位置，同理也能得到数据在 hash 环中的位置，数据存储在顺时针方向遇到的第一台机器中。这种方式使得在机器数量变动时，只有少部分的缓存会失效，避免了缓存雪崩
* **hash 环的偏斜**：机器在 hash 环上的分布不均匀，导致大量的缓存集中在某几台机器上，这时可以使用虚拟节点的方式，将物理机器映射成均匀分布在环中的多个虚拟节点，使得缓存分布均匀

### 3.2 缓存读写一致性策略

需要明确的是，如果对数据库有强一致性要求，那么就不能使用缓存，Redis 只能保证最终一致性

#### 3.2.1 Cache Aside

适合读多写少，因为写多时缓存会频繁被删除，影响缓存命中率

##### 删除而代替更新

* 删除相较于更新更简单，但会造成一次 cache miss，极限情况下会造成缓存击穿
* 更新缓存在写写并发下会有问题：
	1. A 写缓存 10｜A 写 db 10
	2. B 写缓存 20｜B 写 db 20
	3. B 写 db 20｜B 写缓存 20
	4. A 写缓存 10｜A 写缓存 10

##### 先更新数据库再删缓存

问题：
* 删除缓存失败
解决：
* 可以使用较短的过期时间
* 删除失败后默认重试一次，重试失败则写入 mq，恢复后消费消息删掉这些缓存，删除失败再重复此流程

##### 先删缓存在更新数据库

问题：
* 高并发中放大不一致问题
	1. A 删缓存
	2. B cache miss 读 db
	3. B 更新 cache 为 20
	4. A 更新 db 为 21
解决：
* 再删一次

#### 3.2.2 Read/Write Through

应用程序直接和缓存打交道，缓存组件自行维护缓存和数据库的一致性，本地缓存可以使用

#### 3.2.3 Write Back

* 只更新缓存不更新数据库
* 异步将数据刷新回数据库

适合写多的场景，速度快，但会造成一定程度的数据丢失

### 3.3 缓存淘汰策略

#### 3.3.1 LRU

* 基本数据结构
	* map1：根据 key O(1) 获取 value
	* map2：根据 key O(1) 获取 node
	* 双向链表：O(1) 做删除
* put：
	* 如果 key 存在，则删掉 node，移动至头部，map 更新 value
	* 如果缓存满，则删掉 last node，新 node 头插，map 增加 kv
	* 否则新 node 头插，map 增加 kv
* get：
	* 获取 value
	* 执行 key 存在时的 put

#### 3.3.2 LFU

* 基本数据结构
	* mapK2V：根据 key O(1) 获取 value
	* mapK2F：根据 key O(1) 获取 freq
	* minFreq：记录当前最小 freq
	* mapF2K：
		* 根据 key O(1) 获取 freq 对应的 key 集合
		* value 为 LinkedHashSet
			* key 有序，可以 O(1) 删除最不常使用的 key
			* 快速定位 key，因为某个 key 被访问时，freq 会 +1，就需要从该 freq 对应的 key 集合中删除
* put：
	* 如果 key 存在，增加 freq
		* 从 freq 对应的 key 集合删除该 key
		* 在 freq + 1 对应的 key 集合增加该 key
		* 更新 minFreq
	* 如果缓存满，删除 minFreq 对应 key 集合中最早访问的 key
		* mapK2V & mapK2F删除该 key
	* 否则保存该 kv
		* minFreq 置 1
		* 三个 map 增加此 key
* get：
	* 获取 value
	* 执行 key 存在时的 put

## 4. 分布式 Session

借助 Redis 实现：

1. 当用户登录时，使用分布式 ID 生成器作为 key，将查找到的用户 id 作为 value 存入 Redis，设置过期时间
2. 将 key 放入 Cookie 中返回客户端
3. 登录成功访问其他页面时，前端使用拦截器将之前 Cookie 中拿到的 Session id 一并发送至后端
4. 后端拿到 Session id 在 Redis 中查找即可

需要注意的：

* 用户在操作的过程中 key 过期，用户被强制退出：key 中加入时间戳，每次查询时查看过期时间与当前时间的差值，如果小于某个值，刷新 key 即可