# MySQL 并发

---

## 1. 事务

事务：数据库执行过程中的逻辑单元

**原子性**（Atomicity）：事务是不可分割的最小单元。
**一致性**（Consistency）：无论事务执行成功与否，数据库都会处在一个一致的状态。
**隔离性**（Isolation）：各个事务在执行过程中互不干扰互不影响。
**持久性**（Durability）：事务一旦执行成功，则它对数据库中的对应数据的状态的变更就会永久保存到数据库中。

如何理解事务的 ACID 特性：

* 只有满足一致性，事务的执行结果才是正确的
* 无并发时，只需要满足原子性就一定能保证一致性，因为此时默认的串行执行就可以保证隔离性
* **有并发时，需要同时满足隔离性与原子性才行**
* 事务的持久性是为了应对数据库崩溃的状况

## 2. 并发问题

### 2.1 隔离性与并发的取舍

存在并发时需要同时满足隔离性和原子性：

* 事务可以保证操作是原子性的
* 要保证隔离性，最直接的是一个事务在访问数据时，令其他要対这些数据操作的事务进行排队，多个事务呈现串行化执行

可见串行化和事务可以保证并发操作时不会出现一致性问题，但是串行化过于影响性能，所以**舍弃一部分隔离性来提高并发性**。

### 2.2 并发问题与隔离性的体现

牺牲一部分隔离性后，并发事务访问数据就会出现多种问题，主要有以下三种情况：

并发读：读操作不会影响记录，所以允许这种情况发生。

并发写：多个事务対同一记录进行写操作时会出现丢失更新的问题。

* **第二类丢失更新**：一个事务的更新覆盖了另一个事务提交的更新
  | T1（写）      | T2（写）      |                                   |
  | ------------- | ------------- | --------------------------------- |
  | BEGIN         |               |
  |               | BEGIN         |
  | 查询余额 1000 |               |
  |               | 查询余额 1000 |
  |               | 转入 100      |
  |               | COMMIT        |
  | 转出 100      |               |
  | COMMIT        |               | T1 的转出操作覆盖了 T2 的转入操作 |
* **第一类丢失更新**：一个事务的更新覆盖了另一个事务提交的更新，并且进行了回滚，则两次更新操作都丢失了
  | T1（写）      | T2（写）      |                                                                             |
  | ------------- | ------------- | --------------------------------------------------------------------------- |
  | BEGIN         |               |
  |               | BEGIN         |
  | 查询余额 1000 |               |
  |               | 查询余额 1000 |
  |               | 转入 100      |
  |               | COMMIT        |
  | 转出 100      |               |
  | COMMIT        |               |
  | ROLLBACK      |               | T1 的转出操作覆盖了 T2 的转入操作，并且 T1 的回滚操作又覆盖了 T1 的转出操作 |

并发读写：一个事务读一个事务写，这时会出现脏读、不可重复读、幻读。

* **脏读**：一个事务读到了另一个事务回滚前的脏数据
  | T1（写）             | T2（读）     |                           |
  | -------------------- | ------------ | ------------------------- |
  | BEGIN                |              |
  |                      | BEGIN        |
  | 更新余额 1000 -> 900 |              |
  |                      | 查询余额 900 |
  |                      | COMMIT       |
  | ROLLBACK             |              | T2 读到了不存在的余额 900 |

* **不可重复读**：一个事务多次读取表中的同一行数据，读取的结果不同
  | T1（写） | T2（读）      |                                            |
  | -------- | ------------- | ------------------------------------------ |
  | BEGIN    | BEGIN         |
  |          | 查询余额 1000 |
  | 转出 100 |               |
  | COMMIT   |               |
  |          | 查询余额 900  | 同一个事务 T2 中两次対余额的查询发生了变化 |

* **幻读**：一个事务内前后两次查询同一范围的数据，后一次查询看到了前一次查询没有看到的行
  | T1（写）   | T2（读）              |                                                   |
  | ---------- | --------------------- | ------------------------------------------------- |
  | BEGIN      | BEGIN                 |
  |            | SELECT *（1000 rows） |
  | 插入新用户 |                       |
  | COMMIT     |                       |
  |            | SELECT *（1001 rows） | T2 中第二次対相同范围的查询查出了第一次没有的记录 |

针对不同的并发问题，SQL 标准规定了不同的事务隔离级别，不同的隔离级别下解决了不同的并发问题。**事务的隔离级别就是在不同程度下舍弃隔离性从而提升并发的具体表现**：

|                  | 脏读 | 不可重复读 | 幻读 |
| ---------------- | ---- | ---------- | ---- |
| READ UNCOMMITTED | no   | no         | no   |
| READ COMMITTED   | yes  | no         | no   |
| REPEATABLE READ  | yes  | yes        | no   |
| SERIALIZABLE     | yes  | yes        | yes  |

需要注意的几点：

* MySQL 的默认隔离级别为 RR
* 并发写问题（丢失更新）在任何一种隔离级别下都不允许发生
* **不同的数据库対 SQL 标准规定的隔离级别的实现不同，比如 MySQL 在 REPEATABLE READ 下就可以避免幻读**
* 串行化可以避免所有问题，这也对应了之前所说的：串行化和事务可以保证并发操作时不会出现一致性问题

## 3. 并发问题在不同隔离级别下是如何解决的

根据前文叙述，需要解决的并发问题分为并发写和并发读写。

### 3.1 并发写

并发写会产生丢失更新这种严重问题，所以任何隔离级别下都不允许发生，避免的方式就是在多个未提交的事务并发写同一记录时，令它们排队执行，排队的过程通过加锁来实现。

### 3.2 并发读写

显然如果并发读写也通过加锁的方式来串行化执行是不会产生并发问题的，但是会降低并发度，所以 MySQL 中的 InnoDB 通过 MVCC 来解决并发读写的问题。

**MVCC 的作用就是令读写操作可以不用加锁地并发执行，避免了并发问题，提高了并发度，并在此基础之上实现了不同的隔离级别**。

#### 3.2.1 MVCC 的基础：版本链

对于 InnoDB 来说，聚簇索引数据页的记录中包含两个隐藏列：

* trx_id：当前操作记录的事务 id。只有写操作（UPDATE、INSERT、DEELTE）才会被分配 trx_id，而读操作默认为 0
* roll_pointer：修改记录时，旧版本的记录会被写入 undo log 中，这个字段指向 undo log 中的旧版本记录

**每次修改都会将旧版本的这条记录写入 undo log，多次修改后这些记录组成了由 roll_pointer 连接的版本链，而链表头就是最新的记录**。

#### 3.2.2 MVCC 的实现：ReadView

**目的**：为了实现不同的隔离级别，MVCC 的核心问题就是**判断当前事务对其他哪些事务的修改可见、对哪些事务的修改不可见，即能够读取记录版本链中的哪些数据**，InnoDB 中借助 ReadView 来解决这个问题。

**何时生成 Readview**：

1. 对于 RC，事务开启后**每**一次快照读都会生成新的 Readview
2. 对于 RR，事务开启后**第**一次快照读生成，Readview，之后的快照读都是用之前的 Readview

> **快照读**：即不加锁的非阻塞读，通过快照读的方式读到的并不一定是数据的最新版本，而是当前事务可见的最新版本

**Readview 是什么**：

本质上，Readview 就是一个类对象，记录了创建时 mysql 中最大的事务 ID、创建时所有的活跃事务集合等创建时的信息：

* id：生成该 Readview 的事务 id
* m_ids：生成 ReadView 时，活跃的读写事务 id 数组，有序存储（“活跃”指启动了但还未提交）
* m_low_limit_id：生成 ReadView 时系统中应该分配给下一个事务的 id 值
* m_up_limit_id：m_ids 中的最小值，如果为空，表示当前没有活跃读写事务，则设置为当前最大事务 id

SELECT 时记录的可见性规则如下：

* trx_id == id：当前事务在访问自己修改过的记录，可访问
* trx_id < m_up_limit_id：trx_id 代表的事务在创建 ReadView 时已经提交了，对当前事务可见
* trx_id >= m_low_limit_id：trx_id 代表的事务是在创建 Readview 之后开启的，对当前事务不可见
* m_up_limit_id <= trx_id < m_low_limit_id：如果 trx_id 属于 m_ids，说明创建 Readview 时该事务是活跃的，其做的变更对当前视图不可见；否则可见

**MVCC 如何实现快照读**：

1. 开启一个事务 A 更新一条数据，在写入对应 undo log 后，将这行记录（record_version_a）的 DB_TRX_ID 更新为当前事务 A 的 id，用来表明当前更新该数据的事务是事务 A
2. 开启另一个事务 B 以快照读的方式去 select 数据，此时生成事务 B 的 Readview，读到该行数据 record_version_a 的 DB_TRX_ID 为事务 A 的事务 ID，这就说明 record_version_a 是事务 A 修改并提交的
3. 根据事务 B 的 Readview 可以判断事务 B 是否对事务 A 的修改可见
     * 假设可见，则 select 结果即为 record_version_a
     * 假设不可见，则需要根据 undo log 找到历史版本（record_version_x），record_version_x 的 DB_TRX_ID 为事务 X 的事务 id，说明 record_version_x 是事务 X 修改并提交的
4. 如果不可见，则继续寻找下一个历史版本，直到可见为止

**RC 的实现**：一个事务中每次 SELECT 时都会成一个新的 ReadView，对于未提交的事务，trx_id 满足 m_up_limit_id <= trx_id < m_low_limit_id 并且属于 m_ids，根据版本可见性规则，这个版本数据对其他事务不可见，避免了脏读。

**RR 的实现**：一个事务中只有第一次 SELECT 时会生成 ReadView，之后都是复用之前的，从而避免了不可重复读和幻读（**这里的幻读指前文中举例的 select 导致的幻读，而对于 insert / update 导致的幻读无法避免**）。

**RU**：RU 下脏读、不可重复读、幻读都不可避免，而这三种问题其实都反映了同一个现象：读取到了最新的（未提交的事务修改的）数据，対应到 MVCC 中，直接读取版本链链表头的最新记录即可。

**串行化**：MVCC 无法实现，InnoDB 采用加锁的方式来保证串行化。

需要明确的是，不管是一个事务读另一个事务正在写的记录，还是一个事务写另一个事务正在读的记录，写操作的对象是版本链上处于头节点的最新版本，而读操作读取的是历史版本，这种方式在 RU、RC、RR 下都不会产生矛盾。

## 4. 锁

首先需要明确的是：

* **锁是除了 MVCC 之外另一种解决并发问题的方式**，有些场景下如果既不能读取正在被操作的记录，也不允许读取旧版本，那么就需要対读写操作加锁来同步执行顺序
* MVCC 中的读操作（SELECT）称为一致性读 / 快照读，也就是说不会在读数据时加锁，读取的数据不是最新版本，所以 MVCC 的读写操作才不会发生冲突，可以避免 SELECT 导致的幻读
* 如果使用加锁的 SELECT 则会读到最新的数据，导致各种并发读写问题

### 4.1 读写锁

|                   | 读锁（Shared） | 写锁（Exclusive） |
| ----------------- | -------------- | ----------------- |
| 读锁（Shared）    | 兼容           | 不兼容            |
| 写锁（Exclusive） | 不兼容         | 不兼容            |

### 4.2 封锁协议

封锁协议就是使用读写锁来避免并发问题的一系列规则，从而体现出不同的隔离级别。

**一级封锁协议（RU）**：写数据之前加写锁，直到事务结束才释放。

* 过程中其他事务无法写此数据，可防止丢失更新。其中事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）
* 在一级封锁协议中，如果仅仅是读数据而不对其进行修改，是不需要加读锁的，所以会产生脏读和不可重复读

**二级封锁协议（RC）**：在一级封锁协议的基础上，读其他事务正在写的数据之前加读锁，读完立刻释放锁。

* 由于读完后立即释放读锁，而不是等到整个事务结束，所以其他事务仍旧有可能加写锁并修改数据，再次读会发现数据变化，发生了不可重复读

**三级封锁协议（RR）**：与二级封锁协议不同的是将读锁从读完立即释放变为了事务结束再释放，防止了不可重复读，但无法避免幻读。

**两段锁协议（S）**：将事务分成两个阶段，加锁阶段和解锁阶段

* 扩展阶段：在对任何数据进行读、写操作之前，首先要申请并获得该数据的锁
* 收缩阶段：在释放一个锁之后，事务不再申请和获得其他锁

事务遵守两段锁协议是串行化的充分条件，所以能够避免幻读，但不是必要条件。

### 4.3 锁的粒度

锁可以対单独的行或者整张表进行作用，读写锁就可以対行和表进行加锁，兼容的锁可以穿透表锁到达行锁，如加了表锁 S，则可以继续加表锁 S，也可以加行锁 S，而排斥所有写锁。

但是如果想加表锁 X，则需要判读每一行是否有锁，为了避免这种遍历，引入意向锁（Intention Locks）。意向锁属于表锁，可以快速判断表记录中是否存在行锁，省去了判断每一行的过程。

### 4.4 悲观锁与乐观锁

**悲观锁**：认为数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改是大概率的，因此在整个数据处理过程中，将数据处于锁定状态。

**乐观锁**：大多是基于数据版本记录机制实现，如 MVCC。

### 4.5  InnoDB 中的锁

#### 4.5.1 表锁

不使用索引时自动加表锁，因为 InnoDB 的行锁是通过给索引加锁实现的，如果不通过索引条件检索数据，那么 InnoDB 查找记录就需要扫描全表，要扫描全表，就需要锁定表。

#### 4.5.2 Record Lock

* SELECT 读锁：

  ```sql
  select ... lock in share mode
  ```

* SELECT 写锁：

  ```sql
  select ... for update
  ```

* DELETE、UPDATE 会默认加写锁，INSERT 默认加隐式锁，所以 MVCC 无法避免 INSERT 和 UPDATE 导致的幻读，需要间隙锁配合

#### 4.5.3 Gap Lock

* 除了对唯一索引的精确搜索（=或者 in）外都会获取 gap 锁，即锁住其扫描的范围
* 只有在 Read Repeatable、Serializable 隔离级别才有，假设 id 有 3,4,5，锁定 id>3 的数据，是指的 4，5 及后面的数字都会被锁定

#### 4.5.4 Next-Key Lock

next-key lock 是 record lock + gap lock，作用是防止幻读

* 对于主键或唯一索引，如果当前读时，where 条件全部精确命中 (=或者 in)，这种场景加 record lock：某表数据唯一索引 2,6,9,11,15，sql 语句 delete from tb1 where id=9，要操作唯一索引列 9 的数据，利用行锁锁定 id 等于 9 的数据
* 对于主键或唯一索引，如果 where 条件部分命中 (>、<、like 等）或者全未命中，则会在加 gap lock：某表数据唯一索引 2,6,9,11,15，sql 语句 delete from tb1 where id>9，要操作唯一索引列大于 9 的数据，gap 锁将会锁定的列是 (9,+∞)，该区间内无法插入数据
* 非唯一索引列，如果 where 条件命中 (=、in、>、<、like 等）或者全未命中，则会在附近加 gap lock：某表数据非唯一索引 2,6,9,9,11,15，sql 语句 delete from tb1 where id=9，要操作非唯一索引列 9 的数据，gap 锁将会锁定的列是 (6,11]，该区间内无法插入数据
* 没有索引的列，当前读操作时，会加全表 gap lock

#### 4.5.5 隐式锁

如果一个事务新插入一条记录，这条记录没有关联任何锁，会出现并发问题：

* 使用加锁的 SELECT 会出现并发读问题
* 修改这条记录会出现丢失更新

所以事务会对新插入的记录不显式地加锁，防止上述情况发生。

### 4.6 MyISAM 中的锁

MyISAM 不支持行锁，执行 SQL 时自动加表锁，SELECT 加读锁，UPDATE、INSERT、DELETE 加写锁。
